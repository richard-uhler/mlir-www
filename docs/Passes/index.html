<!doctype html><html lang=en-us><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,maximum-scale=1,user-scalable=no"><title>Passes - MLIR</title><meta name=description content="Multi-Level IR Compiler Framework"><meta name=generator content="Hugo 0.64.1"><link href=https://mlir.llvm.org/index.xml rel=alternate type=application/rss+xml><link rel=canonical href=https://mlir.llvm.org/docs/Passes/><link rel=stylesheet href=https://mlir.llvm.org/css/theme.css><script src=https://use.fontawesome.com/releases/v5.0.6/js/all.js></script><link rel=stylesheet href=https://mlir.llvm.org/css/chroma.min.css><script src=https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js></script><script src=https://cdn.jsdelivr.net/npm/jquery.easing@1.4.1/jquery.easing.min.js></script><script src=https://mlir.llvm.org/js/bundle.js></script><style>:root{}</style></head><body><div class=container><header><h1><div><img src=https://mlir.llvm.org//mlir-logo.png width=40px align=absmiddle>
MLIR</div></h1><p class=description>Multi-Level IR Compiler Framework</p></header><div class=global-menu><nav><ul><li class=parent><a href>Community<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=https://llvm.discourse.group/c/mlir/31>Forums</a></li><li class=child><a href=https://discord.gg/xS7Z362>Chat</a></li></ul></li><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li class=parent><a href=https://github.com/llvm/llvm-project/tree/master/mlir>Source<i class="fas fa-angle-right"></i></a><ul class=sub-menu><li class=child><a href=/doxygen/>Doxygen</a></li><li class=child><a href=https://github.com/llvm/llvm-project/tree/master/mlir>GitHub</a></li></ul></li><li><a href="https://bugs.llvm.org/buglist.cgi?bug_status=__open__&list_id=177877&order=changeddate%20DESC%2Cpriority%2Cbug_severity&product=MLIR&query_format=specific">Bugs</a></li></ul></nav></div><div class=content-container><main><h1>Passes</h1><p>This document describes the available MLIR passes and their contracts.</p><p><nav id=TableOfContents><ul><li><a href=#general-transformation-passes>General Transformation Passes</a><ul><li><a href=#-affine-loop-fusion-fuse-affine-loop-nests>-affine-loop-fusion: Fuse affine loop nests</a></li><li><a href=#-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy>-affine-pipeline-data-transfer: Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy</a></li><li><a href=#-buffer-deallocation-adds-all-required-dealloc-operations-for-all-allocations-in-the-input-program>-buffer-deallocation: Adds all required dealloc operations for all allocations in the input program</a></li><li><a href=#-buffer-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-into-common-dominators-and-out-of-nested-regions>-buffer-hoisting: Optimizes placement of allocation operations by moving them into common dominators and out of nested regions</a></li><li><a href=#-buffer-loop-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-out-of-loop-nests>-buffer-loop-hoisting: Optimizes placement of allocation operations by moving them out of loop nests</a></li><li><a href=#-buffer-results-to-out-params-converts-memref-typed-function-results-to-out-params>-buffer-results-to-out-params: Converts memref-typed function results to out-params</a></li><li><a href=#-canonicalize-canonicalize-operations>-canonicalize: Canonicalize operations</a></li><li><a href=#-copy-removal-remove-the-redundant-copies-from-input-ir>-copy-removal: Remove the redundant copies from input IR</a></li><li><a href=#-cse-eliminate-common-sub-expressions>-cse: Eliminate common sub-expressions</a></li><li><a href=#-finalizing-bufferize-finalize-a-partial-bufferization>-finalizing-bufferize: Finalize a partial bufferization</a></li><li><a href=#-inline-inline-function-calls>-inline: Inline function calls</a></li><li><a href=#-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop>-loop-coalescing: Coalesce nested loops with independent bounds into a single loop</a></li><li><a href=#-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop>-loop-invariant-code-motion: Hoist loop invariant instructions outside of the loop</a></li><li><a href=#-memref-dataflow-opt-perform-storeload-forwarding-for-memrefs>-memref-dataflow-opt: Perform store/load forwarding for memrefs</a></li><li><a href=#-normalize-memrefs-normalize-memrefs>-normalize-memrefs: Normalize memrefs</a></li><li><a href=#-strip-debuginfo-strip-debug-info-from-all-operations>-strip-debuginfo: Strip debug info from all operations</a></li><li><a href=#-symbol-dce-eliminate-dead-symbols>-symbol-dce: Eliminate dead symbols</a></li></ul></li><li><a href=#conversion-passes>Conversion Passes</a><ul><li><a href=#-convert-affine-for-to-gpu-convert-top-level-affinefor-ops-to-gpu-kernels>-convert-affine-for-to-gpu: Convert top-level AffineFor Ops to GPU kernels</a></li><li><a href=#-convert-async-to-llvm-convert-the-operations-from-the-async-dialect-into-the-llvm-dialect>-convert-async-to-llvm: Convert the operations from the async dialect into the LLVM dialect</a></li><li><a href=#-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call>-convert-gpu-launch-to-vulkan-launch: Convert gpu.launch_func to vulkanLaunch external call</a></li><li><a href=#-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations>-convert-gpu-to-nvvm: Generate NVVM operations for gpu operations</a></li><li><a href=#-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations>-convert-gpu-to-rocdl: Generate ROCDL operations for gpu operations</a></li><li><a href=#-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect>-convert-gpu-to-spirv: Convert GPU dialect to SPIR-V dialect</a></li><li><a href=#-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect>-convert-linalg-to-llvm: Convert the operations from the linalg dialect into the LLVM dialect</a></li><li><a href=#-convert-linalg-to-spirv-convert-linalg-ops-to-spir-v-ops>-convert-linalg-to-spirv: Convert Linalg ops to SPIR-V ops</a></li><li><a href=#-convert-linalg-to-std-convert-the-operations-from-the-linalg-dialect-into-the-standard-dialect>-convert-linalg-to-std: Convert the operations from the linalg dialect into the Standard dialect</a></li><li><a href=#-convert-openmp-to-llvm-convert-the-openmp-ops-to-openmp-ops-with-llvm-dialect>-convert-openmp-to-llvm: Convert the OpenMP ops to OpenMP ops with LLVM dialect</a></li><li><a href=#-convert-parallel-loops-to-gpu-convert-mapped-scfparallel-ops-to-gpu-launch-operations>-convert-parallel-loops-to-gpu: Convert mapped scf.parallel ops to gpu launch operations</a></li><li><a href=#-convert-pdl-to-pdl-interp-convert-pdl-ops-to-pdl-interpreter-ops>-convert-pdl-to-pdl-interp: Convert PDL ops to PDL interpreter ops</a></li><li><a href=#-convert-scf-to-openmp-convert-scf-parallel-loop-to-openmp-parallel--workshare-constructs>-convert-scf-to-openmp: Convert SCF parallel loop to OpenMP parallel + workshare constructs.</a></li><li><a href=#-convert-scf-to-std-convert-scf-dialect-to-standard-dialect-replacing-structured-control-flow-with-a-cfg>-convert-scf-to-std: Convert SCF dialect to Standard dialect, replacing structured control flow with a CFG</a></li><li><a href=#-convert-shape-constraints-convert-shape-constraint-operations-to-the-standard-dialect>-convert-shape-constraints: Convert shape constraint operations to the standard dialect</a></li><li><a href=#-convert-shape-to-std-convert-operations-from-the-shape-dialect-into-the-standard-dialect>-convert-shape-to-std: Convert operations from the shape dialect into the standard dialect</a></li><li><a href=#-convert-spirv-to-llvm-convert-spir-v-dialect-to-llvm-dialect>-convert-spirv-to-llvm: Convert SPIR-V dialect to LLVM dialect</a></li><li><a href=#-convert-std-to-llvm-convert-scalar-and-vector-operations-from-the-standard-to-the-llvm-dialect>-convert-std-to-llvm: Convert scalar and vector operations from the Standard to the LLVM dialect</a></li><li><a href=#-convert-std-to-spirv-convert-standard-ops-to-spir-v-dialect>-convert-std-to-spirv: Convert Standard Ops to SPIR-V dialect</a></li><li><a href=#-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect>-convert-vector-to-llvm: Lower the operations from the vector dialect into the LLVM dialect</a></li><li><a href=#-convert-vector-to-rocdl-lower-the-operations-from-the-vector-dialect-into-the-rocdl-dialect>-convert-vector-to-rocdl: Lower the operations from the vector dialect into the ROCDL dialect</a></li><li><a href=#-convert-vector-to-scf-lower-the-operations-from-the-vector-dialect-into-the-scf-dialect>-convert-vector-to-scf: Lower the operations from the vector dialect into the SCF dialect</a></li><li><a href=#-convert-vector-to-spirv-lower-the-operations-from-the-vector-dialect-into-the-spir-v-dialect>-convert-vector-to-spirv: Lower the operations from the vector dialect into the SPIR-V dialect</a></li><li><a href=#-gpu-to-llvm-convert-gpu-dialect-to-llvm-dialect-with-gpu-runtime-calls>-gpu-to-llvm: Convert GPU dialect to LLVM dialect with GPU runtime calls</a></li><li><a href=#-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls>-launch-func-to-vulkan: Convert vulkanLaunch external call to Vulkan runtime external calls</a></li><li><a href=#-legalize-std-for-spirv-legalize-standard-ops-for-spir-v-lowering>-legalize-std-for-spirv: Legalize standard ops for SPIR-V lowering</a></li><li><a href=#-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-scf-operations>-lower-affine: Lower Affine operations to a combination of Standard and SCF operations</a></li><li><a href=#-lower-host-to-llvm-lowers-the-host-module-code-and-gpulaunch_func-to-llvm>-lower-host-to-llvm: Lowers the host module code and gpu.launch_func to LLVM</a></li></ul></li><li><a href=#async-dialect-passes>async Dialect Passes</a><ul><li><a href=#-async-parallel-for-convert-scfparallel-operations-to-multiple-async-regions-executed-concurrently-for-non-overlapping-iteration-ranges>-async-parallel-for: Convert scf.parallel operations to multiple async regions executed concurrently for non-overlapping iteration ranges</a></li><li><a href=#-async-ref-counting-automatic-reference-counting-for-async-dialect-data-types>-async-ref-counting: Automatic reference counting for Async dialect data types</a></li><li><a href=#-async-ref-counting-optimization-optimize-automatic-reference-counting-operations-for-theasync-dialect-by-removing-redundant-operations>-async-ref-counting-optimization: Optimize automatic reference counting operations for theAsync dialect by removing redundant operations</a></li></ul></li><li><a href=#affine-dialect-passes>affine Dialect Passes</a><ul><li><a href=#-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations>-affine-data-copy-generate: Generate explicit copying for affine memory operations</a></li><li><a href=#-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops>-affine-loop-invariant-code-motion: Hoist loop invariant instructions outside of affine loops</a></li><li><a href=#-affine-loop-normalize-apply-normalization-transformations-to-affine-loop-like-ops>-affine-loop-normalize: Apply normalization transformations to affine loop-like ops</a></li><li><a href=#-affine-loop-tile-tile-affine-loop-nests>-affine-loop-tile: Tile affine loop nests</a></li><li><a href=#-affine-loop-unroll-unroll-affine-loops>-affine-loop-unroll: Unroll affine loops</a></li><li><a href=#-affine-loop-unroll-jam-unroll-and-jam-affine-loops>-affine-loop-unroll-jam: Unroll and jam affine loops</a></li><li><a href=#-affine-parallelize-convert-affinefor-ops-into-1-d-affineparallel>-affine-parallelize: Convert affine.for ops into 1-D affine.parallel</a></li><li><a href=#-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction>-affine-super-vectorize: Vectorize to a target independent n-D vector abstraction</a></li><li><a href=#-simplify-affine-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs>-simplify-affine-structures: Simplify affine expressions in maps/sets and normalize memrefs</a></li></ul></li><li><a href=#gpu-dialect-passes>gpu Dialect Passes</a><ul><li><a href=#-gpu-async-region-make-gpu-ops-async>-gpu-async-region: Make GPU ops async</a></li><li><a href=#-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions>-gpu-kernel-outlining: Outline gpu.launch bodies to kernel functions</a></li></ul></li><li><a href=#linalg-dialect-passes>linalg Dialect Passes</a><ul><li><a href=#-convert-elementwise-to-linalg-convert-elementwisemappable-ops-to-linalg>-convert-elementwise-to-linalg: Convert ElementwiseMappable ops to linalg</a></li><li><a href=#-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops>-convert-linalg-to-affine-loops: Lower the operations from the linalg dialect into affine loops</a></li><li><a href=#-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops>-convert-linalg-to-loops: Lower the operations from the linalg dialect into loops</a></li><li><a href=#-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops>-convert-linalg-to-parallel-loops: Lower the operations from the linalg dialect into parallel loops</a></li><li><a href=#-linalg-bufferize-bufferize-the-linalg-dialect>-linalg-bufferize: Bufferize the linalg dialect</a></li><li><a href=#-linalg-fold-reshape-ops-by-linearization-fold-tensorreshapeops-with-genericindexed-generic-ops-by-linearization>-linalg-fold-reshape-ops-by-linearization: Fold TensorReshapeOps with generic/indexed generic ops by linearization</a></li><li><a href=#-linalg-fold-unit-extent-dims-remove-unit-extent-dimension-in-linalg-ops-on-tensors>-linalg-fold-unit-extent-dims: Remove unit-extent dimension in Linalg ops on tensors</a></li><li><a href=#-linalg-fusion-for-tensor-ops-fuse-operations-on-rankedtensortype-in-linalg-dialect>-linalg-fusion-for-tensor-ops: Fuse operations on RankedTensorType in linalg dialect</a></li><li><a href=#-linalg-generalize-named-ops-convert-named-ops-into-generic-ops>-linalg-generalize-named-ops: Convert named ops into generic ops</a></li><li><a href=#-linalg-promote-subviews-promote-subview-ops-to-local-buffers>-linalg-promote-subviews: Promote subview ops to local buffers</a></li><li><a href=#-linalg-tile-tile-operations-in-the-linalg-dialect>-linalg-tile: Tile operations in the linalg dialect</a></li><li><a href=#-linalg-tile-to-parallel-loops-tile-operations-in-the-linalg-dialect-to-parallel-loops>-linalg-tile-to-parallel-loops: Tile operations in the linalg dialect to parallel loops</a></li></ul></li><li><a href=#llvm-dialect-passes>llvm Dialect Passes</a><ul><li><a href=#-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir>-llvm-legalize-for-export: Legalize LLVM dialect to be convertible to LLVM IR</a></li></ul></li><li><a href=#quant-dialect-passes>quant Dialect Passes</a><ul><li><a href=#-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values>-quant-convert-const: Converts constants followed by qbarrier to actual quantized values</a></li><li><a href=#-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts>-quant-convert-simulated-quantization: Converts training-time simulated quantization ops to corresponding quantize/dequantize casts</a></li></ul></li><li><a href=#reducer-passes>Reducer Passes</a><ul><li><a href=#-opt-reduction-pass-a-reduction-pass-wrapper-for-optimization-passes>-opt-reduction-pass: A reduction pass wrapper for optimization passes</a></li><li><a href=#-reduction-tree-a-general-reduction-tree-pass-for-the-mlir-reduce-tool>-reduction-tree: A general reduction tree pass for the MLIR Reduce Tool</a></li></ul></li><li><a href=#scf-dialect-passes>scf Dialect Passes</a><ul><li><a href=#-for-loop-specialization-specialize-for-loops-for-vectorization>-for-loop-specialization: Specialize for loops for vectorization</a></li><li><a href=#-parallel-loop-fusion-fuse-adjacent-parallel-loops>-parallel-loop-fusion: Fuse adjacent parallel loops</a></li><li><a href=#-parallel-loop-specialization-specialize-parallel-loops-for-vectorization>-parallel-loop-specialization: Specialize parallel loops for vectorization</a></li><li><a href=#-parallel-loop-tiling-tile-parallel-loops>-parallel-loop-tiling: Tile parallel loops</a></li><li><a href=#-scf-bufferize-bufferize-the-scf-dialect>-scf-bufferize: Bufferize the scf dialect.</a></li></ul></li><li><a href=#shape-dialect-passes>shape Dialect Passes</a><ul><li><a href=#-remove-shape-constraints-replace-all-cstr_-ops-with-a-true-witness>-remove-shape-constraints: Replace all cstr_ ops with a true witness</a></li><li><a href=#-shape-bufferize-bufferize-the-shape-dialect>-shape-bufferize: Bufferize the shape dialect.</a></li><li><a href=#-shape-to-shape-lowering-legalize-shape-dialect-to-be-convertible-to-standard>-shape-to-shape-lowering: Legalize Shape dialect to be convertible to Standard</a></li></ul></li><li><a href=#spv-dialect-passes>spv Dialect Passes</a><ul><li><a href=#-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info>-decorate-spirv-composite-type-layout: Decorate SPIR-V composite type with layout info</a></li><li><a href=#-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info>-spirv-lower-abi-attrs: Decorate SPIR-V composite type with layout info</a></li><li><a href=#-spirv-rewrite-inserts-rewrite-sequential-chains-of-spvcompositeinsert-operations-into-spvcompositeconstruct-operations>-spirv-rewrite-inserts: Rewrite sequential chains of spv.CompositeInsert operations into spv.CompositeConstruct operations</a></li><li><a href=#-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops>-spirv-update-vce: Deduce and attach minimal (version, capabilities, extensions) requirements to spv.module ops</a></li></ul></li><li><a href=#standard-dialect-passes>standard Dialect Passes</a><ul><li><a href=#-func-bufferize-bufferize-funccallreturn-ops>-func-bufferize: Bufferize func/call/return ops</a></li><li><a href=#-std-bufferize-bufferize-the-std-dialect>-std-bufferize: Bufferize the std dialect</a></li><li><a href=#-std-expand-legalize-std-operations-to-be-convertible-to-llvm>-std-expand: Legalize std operations to be convertible to LLVM.</a></li><li><a href=#-tensor-constant-bufferize-bufferize-tensor-constants>-tensor-constant-bufferize: Bufferize tensor constants.</a></li></ul></li><li><a href=#tosa-dialect-passes>TOSA Dialect Passes</a><ul><li><a href=#-tosa-make-broadcastable-tosa-rank-reshape-to-enable-broadcasting>-tosa-make-broadcastable: TOSA rank Reshape to enable Broadcasting</a></li></ul></li></ul></nav><h2 id=general-transformation-passes>General Transformation Passes&nbsp;<a class=headline-hash href=#general-transformation-passes>¶</a></h2><h3 id=-affine-loop-fusion-fuse-affine-loop-nests><code>-affine-loop-fusion</code>: Fuse affine loop nests&nbsp;<a class=headline-hash href=#-affine-loop-fusion-fuse-affine-loop-nests>¶</a></h3><h4 id=options>Options&nbsp;<a class=headline-hash href=#options>¶</a></h4><pre><code>-fusion-compute-tolerance   : Fractional increase in additional computation tolerated while fusing
-fusion-fast-mem-space      : Faster memory space number to promote fusion buffers to
-fusion-local-buf-threshold : Threshold size (KiB) for promoting local buffers to fast memory space
-fusion-maximal             : Enables maximal loop fusion
</code></pre><h3 id=-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy><code>-affine-pipeline-data-transfer</code>: Pipeline non-blocking data transfers between explicitly managed levels of the memory hierarchy&nbsp;<a class=headline-hash href=#-affine-pipeline-data-transfer-pipeline-non-blocking-data-transfers-between-explicitly-managed-levels-of-the-memory-hierarchy>¶</a></h3><p>This pass performs a transformation to overlap non-blocking DMA operations
in a loop with computations through double buffering. This is achieved by
advancing dma_start operations with respect to other operations.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@pipelinedatatransfer</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
  <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%1</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
  <span class=nv>%2</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=nv>%c0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
  <span class=nv>%c128</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>128</span> <span class=p>:</span> <span class=k>index</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>8</span> <span class=p>{</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%4</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%4</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%i0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=kt>return</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@pipelinedatatransfer</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
    <span class=nv>%c8</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>8</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%c0_0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%c128</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>128</span> <span class=p>:</span> <span class=k>index</span>
    <span class=nv>%1</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%2</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%c0</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%c0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%c0</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>1</span> to <span class=m>8</span> <span class=p>{</span>
      affine<span class=p>.</span>dma_start <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%arg0</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>]</span><span class=p>,</span> <span class=nv>%2</span><span class=p>[</span><span class=nv>%arg0</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>256x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%8</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map3</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>)</span>
      <span class=nv>%9</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%8</span><span class=p>)</span>
      <span class=nv>%10</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%8</span><span class=p>)</span>
      affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%11</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
      <span class=nv>%12</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%11</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
      affine<span class=p>.</span>store <span class=nv>%12</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%8</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%8</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=p>}</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map3</span><span class=p>(</span><span class=nv>%c8</span><span class=p>)</span>
    <span class=nv>%4</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span>
    <span class=nv>%5</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map4</span><span class=p>(</span><span class=nv>%3</span><span class=p>)</span>
    affine<span class=p>.</span>dma_wait <span class=nv>%2</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> symbol<span class=p>(</span><span class=nv>%c0_0</span><span class=p>)</span><span class=p>]</span><span class=p>,</span> <span class=nv>%c128</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%6</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%1</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=nv>%7</span> <span class=p>=</span> <span class=s>&#34;compute&#34;</span><span class=p>(</span><span class=nv>%6</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=k>f32</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=k>f32</span>
    affine<span class=p>.</span>store <span class=nv>%7</span><span class=p>,</span> <span class=nv>%1</span><span class=p>[</span><span class=nv>%3</span> mod <span class=m>2</span><span class=p>,</span> <span class=nv>%3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    dealloc <span class=nv>%2</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x1x</span><span class=k>f32</span><span class=p>&gt;</span>
    dealloc <span class=nv>%1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x32x</span><span class=k>f32</span><span class=p>,</span> <span class=m>1</span><span class=p>&gt;</span>
    <span class=kt>return</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><h3 id=-buffer-deallocation-adds-all-required-dealloc-operations-for-all-allocations-in-the-input-program><code>-buffer-deallocation</code>: Adds all required dealloc operations for all allocations in the input program&nbsp;<a class=headline-hash href=#-buffer-deallocation-adds-all-required-dealloc-operations-for-all-allocations-in-the-input-program>¶</a></h3><p>This pass implements an algorithm to automatically introduce all required
deallocation operations for all buffers in the input program. This ensures that
the resulting program does not have any memory leaks.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>#map0</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>)</span><span class=p>&gt;</span>
module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@condBranch</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=k>i1</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>{</span>
    cond_br <span class=nv>%arg0</span><span class=p>,</span> <span class=nl>^bb1</span><span class=p>,</span> <span class=nl>^bb2
</span><span class=nl>  </span><span class=nl>^bb1</span><span class=p>:</span>
    br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%arg1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>
  <span class=nl>^bb2</span><span class=p>:</span>
    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    linalg<span class=p>.</span>generic <span class=p>{</span>
      <span class=nl>args_in =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span>
      <span class=nl>args_out =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span>
      <span class=nl>indexing_maps =</span> <span class=p>[</span><span class=nv>#map0</span><span class=p>,</span> <span class=nv>#map0</span><span class=p>]</span><span class=p>,</span>
      <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>]</span><span class=p>}</span> <span class=nv>%arg1</span><span class=p>,</span> <span class=nv>%0</span> <span class=p>{</span>
    <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%gen1_arg0</span><span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>%gen1_arg1</span><span class=p>:</span> <span class=k>f32</span><span class=p>)</span><span class=p>:</span>
      <span class=nv>%tmp1</span> <span class=p>=</span> exp <span class=nv>%gen1_arg0</span> <span class=p>:</span> <span class=k>f32</span>
      linalg<span class=p>.</span>yield <span class=nv>%tmp1</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=p>}</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>
  <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span><span class=p>:</span>
    <span class=s>&#34;linalg.copy&#34;</span><span class=p>(</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>)</span> <span class=p>:</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
    <span class=kt>return</span>
  <span class=p>}</span>
<span class=p>}</span>

</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>#map0</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>d0<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>d0<span class=p>)</span><span class=p>&gt;</span>
module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@condBranch</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=k>i1</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>{</span>
    cond_br <span class=nv>%arg0</span><span class=p>,</span> <span class=nl>^bb1</span><span class=p>,</span> <span class=nl>^bb2
</span><span class=nl>  </span><span class=nl>^bb1</span><span class=p>:</span>  <span class=c>// pred: ^bb0
</span><span class=c></span>    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    linalg<span class=p>.</span>copy<span class=p>(</span><span class=nv>%arg1</span><span class=p>,</span> <span class=nv>%0</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>
  <span class=nl>^bb2</span><span class=p>:</span>  <span class=c>// pred: ^bb0
</span><span class=c></span>    <span class=nv>%1</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    linalg<span class=p>.</span>generic <span class=p>{</span>
      <span class=nl>args_in =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span>
      <span class=nl>args_out =</span> <span class=m>1</span> <span class=p>:</span> <span class=k>i64</span><span class=p>,</span>
      <span class=nl>indexing_maps =</span> <span class=p>[</span><span class=nv>#map0</span><span class=p>,</span> <span class=nv>#map0</span><span class=p>]</span><span class=p>,</span>
      <span class=nl>iterator_types =</span> <span class=p>[</span><span class=s>&#34;parallel&#34;</span><span class=p>]</span><span class=p>}</span> <span class=nv>%arg1</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>{</span>
    <span class=nl>^bb0</span><span class=p>(</span><span class=nv>%arg3</span><span class=p>:</span> <span class=k>f32</span><span class=p>,</span> <span class=nv>%arg4</span><span class=p>:</span> <span class=k>f32</span><span class=p>)</span><span class=p>:</span>  <span class=c>// no predecessors
</span><span class=c></span>      <span class=nv>%4</span> <span class=p>=</span> exp <span class=nv>%arg3</span> <span class=p>:</span> <span class=k>f32</span>
      linalg<span class=p>.</span>yield <span class=nv>%4</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=p>}</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=nv>%2</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    linalg<span class=p>.</span>copy<span class=p>(</span><span class=nv>%1</span><span class=p>,</span> <span class=nv>%2</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    dealloc <span class=nv>%1</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    br <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%2</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span>
  <span class=nl>^bb3</span><span class=p>(</span><span class=nv>%3</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>)</span><span class=p>:</span>  <span class=c>// 2 preds: ^bb1, ^bb2
</span><span class=c></span>    linalg<span class=p>.</span>copy<span class=p>(</span><span class=nv>%3</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span><span class=p>,</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    dealloc <span class=nv>%3</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>2x</span><span class=k>f32</span><span class=p>&gt;</span>
    <span class=kt>return</span>
  <span class=p>}</span>

<span class=p>}</span>
</code></pre></div><h3 id=-buffer-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-into-common-dominators-and-out-of-nested-regions><code>-buffer-hoisting</code>: Optimizes placement of allocation operations by moving them into common dominators and out of nested regions&nbsp;<a class=headline-hash href=#-buffer-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-into-common-dominators-and-out-of-nested-regions>¶</a></h3><p>This pass implements an approach to aggressively move allocations upwards
into common dominators and out of nested regions.</p><h3 id=-buffer-loop-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-out-of-loop-nests><code>-buffer-loop-hoisting</code>: Optimizes placement of allocation operations by moving them out of loop nests&nbsp;<a class=headline-hash href=#-buffer-loop-hoisting-optimizes-placement-of-allocation-operations-by-moving-them-out-of-loop-nests>¶</a></h3><p>This pass implements an approach to aggressively move allocations upwards
out of loop nests. It does not move allocations into common dominators.</p><h3 id=-buffer-results-to-out-params-converts-memref-typed-function-results-to-out-params><code>-buffer-results-to-out-params</code>: Converts memref-typed function results to out-params&nbsp;<a class=headline-hash href=#-buffer-results-to-out-params-converts-memref-typed-function-results-to-out-params>¶</a></h3><p>Some calling conventions prefer to pass output memrefs as &ldquo;out params&rdquo;. The
conversion to this calling convention must be done as an atomic
transformation of the entire program (hence this is a module pass).</p><p>For example, if a call is rewritten, the callee needs to be rewritten
otherwise the IR will end up invalid. Thus, this transformation
require an atomic change to the entire program (e.g. the whole module).</p><p>This pass is expected to run immediately after bufferization is finished.
At that point, tensor-typed results will have been converted to memref-typed
results, and can be consistently converted to out params.</p><p>All memref-typed results are appended to the function argument list.</p><p>The main issue with this pass (and the out-param calling convention) is that
buffers for results need to be allocated in the caller. This currently only
works for static shaped memrefs.</p><h3 id=-canonicalize-canonicalize-operations><code>-canonicalize</code>: Canonicalize operations&nbsp;<a class=headline-hash href=#-canonicalize-canonicalize-operations>¶</a></h3><p>This pass performs various types of canonicalizations over a set of
operations. See
<a href=/docs/Canonicalization/>Operation Canonicalization</a>
for more
details.</p><h3 id=-copy-removal-remove-the-redundant-copies-from-input-ir><code>-copy-removal</code>: Remove the redundant copies from input IR&nbsp;<a class=headline-hash href=#-copy-removal-remove-the-redundant-copies-from-input-ir>¶</a></h3><h3 id=-cse-eliminate-common-sub-expressions><code>-cse</code>: Eliminate common sub-expressions&nbsp;<a class=headline-hash href=#-cse-eliminate-common-sub-expressions>¶</a></h3><p>This pass implements a generalized algorithm for common sub-expression
elimination. This pass relies on information provided by the
<code>Memory SideEffect</code> interface to identify when it is safe to eliminate
operations. See
<a href=https://en.wikipedia.org/wiki/Common_subexpression_elimination>Common subexpression elimination</a>
for more general details on this optimization.</p><h4 id=statistics>Statistics&nbsp;<a class=headline-hash href=#statistics>¶</a></h4><pre><code>num-cse'd : Number of operations CSE'd
num-dce'd : Number of operations DCE'd
</code></pre><h3 id=-finalizing-bufferize-finalize-a-partial-bufferization><code>-finalizing-bufferize</code>: Finalize a partial bufferization&nbsp;<a class=headline-hash href=#-finalizing-bufferize-finalize-a-partial-bufferization>¶</a></h3><p>A bufferize pass that finalizes a partial bufferization by removing
remaining <code>tensor_load</code> and <code>tensor_to_memref</code> operations.</p><p>The removal of those operations is only possible if the operations only
exist in pairs, i.e., all uses of <code>tensor_load</code> operations are
<code>tensor_to_memref</code> operations.</p><p>This pass will fail if not all operations can be removed or if any operation
with tensor typed operands remains.</p><h3 id=-inline-inline-function-calls><code>-inline</code>: Inline function calls&nbsp;<a class=headline-hash href=#-inline-inline-function-calls>¶</a></h3><h4 id=options-1>Options&nbsp;<a class=headline-hash href=#options-1>¶</a></h4><pre><code>-default-pipeline : The default optimizer pipeline used for callables
-op-pipelines     : Callable operation specific optimizer pipelines (in the form of `dialect.op(pipeline)`)
-max-iterations   : Maximum number of iterations when inlining within an SCC
</code></pre><h3 id=-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop><code>-loop-coalescing</code>: Coalesce nested loops with independent bounds into a single loop&nbsp;<a class=headline-hash href=#-loop-coalescing-coalesce-nested-loops-with-independent-bounds-into-a-single-loop>¶</a></h3><h3 id=-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop><code>-loop-invariant-code-motion</code>: Hoist loop invariant instructions outside of the loop&nbsp;<a class=headline-hash href=#-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-the-loop>¶</a></h3><h3 id=-memref-dataflow-opt-perform-storeload-forwarding-for-memrefs><code>-memref-dataflow-opt</code>: Perform store/load forwarding for memrefs&nbsp;<a class=headline-hash href=#-memref-dataflow-opt-perform-storeload-forwarding-for-memrefs>¶</a></h3><p>This pass performs store to load forwarding for memref&rsquo;s to eliminate memory
accesses and potentially the entire memref if all its accesses are
forwarded.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@store_load_affine_apply</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
  <span class=nv>%cf7</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>7.0</span> <span class=p>:</span> <span class=k>f32</span>
  <span class=nv>%m</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
  affine<span class=p>.</span>for <span class=nv>%i0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%i1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
      affine<span class=p>.</span>store <span class=nv>%cf7</span><span class=p>,</span> <span class=nv>%m</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%v0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%m</span><span class=p>[</span><span class=nv>%i0</span><span class=p>,</span> <span class=nv>%i1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
      <span class=nv>%v1</span> <span class=p>=</span> addf <span class=nv>%v0</span><span class=p>,</span> <span class=nv>%v0</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=p>}</span>
  <span class=p>}</span>
  <span class=kt>return</span> <span class=nv>%m</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir>module <span class=p>{</span>
  <span class=kt>func</span> <span class=nf>@store_load_affine_apply</span><span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span> <span class=p>{</span>
    <span class=nv>%cst</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>7.000000e+00</span> <span class=p>:</span> <span class=k>f32</span>
    <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
    affine<span class=p>.</span>for <span class=nv>%arg0</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
      affine<span class=p>.</span>for <span class=nv>%arg1</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>10</span> <span class=p>{</span>
        affine<span class=p>.</span>store <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%0</span><span class=p>[</span><span class=nv>%arg0</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
        <span class=nv>%1</span> <span class=p>=</span> addf <span class=nv>%cst</span><span class=p>,</span> <span class=nv>%cst</span> <span class=p>:</span> <span class=k>f32</span>
      <span class=p>}</span>
    <span class=p>}</span>
    <span class=kt>return</span> <span class=nv>%0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>10x10x</span><span class=k>f32</span><span class=p>&gt;</span>
  <span class=p>}</span>
<span class=p>}</span>
</code></pre></div><h3 id=-normalize-memrefs-normalize-memrefs><code>-normalize-memrefs</code>: Normalize memrefs&nbsp;<a class=headline-hash href=#-normalize-memrefs-normalize-memrefs>¶</a></h3><p>This pass transforms memref types with a non-trivial
<a href=https://mlir.llvm.org/docs/LangRef/#layout-map>layout map</a>
into
memref types with an identity layout map, e.g. (i, j) -> (i, j). This
pass is inter-procedural, in the sense that it can modify function
interfaces and call sites that pass memref types. In order to modify
memref types while preserving the original behavior, users of those
memref types are also modified to incorporate the resulting layout map.
For instance, an [AffineLoadOp]
(<a href=https://mlir.llvm.org/docs/Dialects/Affine/#affineload-affineloadop>https://mlir.llvm.org/docs/Dialects/Affine/#affineload-affineloadop</a>)
will be updated to compose the layout map with with the affine expression
contained in the op. Operations marked with the [MemRefsNormalizable]
(<a href=https://mlir.llvm.org/docs/Traits/#memrefsnormalizable>https://mlir.llvm.org/docs/Traits/#memrefsnormalizable</a>) trait are
expected to be normalizable. Supported operations include affine
operations, std.alloc, std.dealloc, and std.return.</p><p>Given an appropriate layout map specified in the code, this transformation
can express tiled or linearized access to multi-dimensional data
structures, but will not modify memref types without an explicit layout
map.</p><p>Currently this pass is limited to only modify
functions where all memref types can be normalized. If a function
contains any operations that are not MemRefNormalizable, then the function
and any functions that call or call it will not be modified.</p><p>Input</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>#tile</span> <span class=p>=</span> affine_map<span class=p>&lt;</span><span class=p>(</span>i<span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span>i floordiv <span class=m>4</span><span class=p>,</span> i mod <span class=m>4</span><span class=p>)</span><span class=p>&gt;</span>
<span class=kt>func</span> <span class=nf>@matmul</span><span class=p>(</span><span class=nv>%A</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span><span class=p>,</span>
             <span class=nv>%B</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%C</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>{</span>
  affine<span class=p>.</span>for <span class=nv>%arg3</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>16</span> <span class=p>{</span>
        <span class=nv>%a</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%A</span><span class=p>[</span><span class=nv>%arg3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
        <span class=nv>%p</span> <span class=p>=</span> mulf <span class=nv>%a</span><span class=p>,</span> <span class=nv>%a</span> <span class=p>:</span> <span class=k>f64</span>
        affine<span class=p>.</span>store <span class=nv>%p</span><span class=p>,</span> <span class=nv>%A</span><span class=p>[</span><span class=nv>%arg3</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=nv>%c</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
  <span class=nv>%d</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%c</span><span class=p>[</span><span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
  <span class=kt>return</span> <span class=nv>%A</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>,</span> <span class=nv>#tile</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@matmul</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span><span class=p>,</span> <span class=nv>%arg1</span><span class=p>:</span> <span class=k>index</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>16x</span><span class=k>f64</span><span class=p>&gt;</span><span class=p>)</span>
  <span class=p>-&gt;</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span> <span class=p>{</span>
  affine<span class=p>.</span>for <span class=nv>%arg3</span> <span class=p>=</span> <span class=m>0</span> to <span class=m>16</span> <span class=p>{</span>
    <span class=nv>%3</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg3</span> floordiv <span class=m>4</span><span class=p>,</span> <span class=nv>%arg3</span> mod <span class=m>4</span><span class=p>]</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
    <span class=nv>%4</span> <span class=p>=</span> mulf <span class=nv>%3</span><span class=p>,</span> <span class=nv>%3</span> <span class=p>:</span> <span class=k>f64</span>
    affine<span class=p>.</span>store <span class=nv>%4</span><span class=p>,</span> <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg3</span> floordiv <span class=m>4</span><span class=p>,</span> <span class=nv>%arg3</span> mod <span class=m>4</span><span class=p>]</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
  <span class=p>}</span>
  <span class=nv>%0</span> <span class=p>=</span> alloc<span class=p>(</span><span class=p>)</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
  <span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>apply <span class=nv>#map1</span><span class=p>(</span><span class=p>)</span>
  <span class=nv>%2</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%0</span><span class=p>[</span><span class=m>0</span><span class=p>,</span> <span class=m>0</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
  <span class=kt>return</span> <span class=nv>%arg0</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>4x4x</span><span class=k>f64</span><span class=p>&gt;</span>
<span class=p>}</span>
</code></pre></div><p>Input</p><pre><code>#linear8 = affine_map&lt;(i, j) -&gt; (i * 8 + j)&gt;
func @linearize(%arg0: memref&lt;8x8xi32, #linear8&gt;,
                %arg1: memref&lt;8x8xi32, #linear8&gt;,
                %arg2: memref&lt;8x8xi32, #linear8&gt;) {
  %c8 = constant 8 : index
  %c0 = constant 0 : index
  %c1 = constant 1 : index
  affine.for %arg3 = %c0 to %c8  {
  affine.for %arg4 = %c0 to %c8  {
    affine.for %arg5 = %c0 to %c8 {
      %0 = affine.load %arg0[%arg3, %arg5] : memref&lt;8x8xi32, #linear8&gt;
      %1 = affine.load %arg1[%arg5, %arg4] : memref&lt;8x8xi32, #linear8&gt;
      %2 = affine.load %arg2[%arg3, %arg4] : memref&lt;8x8xi32, #linear8&gt;
      %3 = muli %0, %1 : i32
      %4 = addi %2, %3 : i32
      affine.store %4, %arg2[%arg3, %arg4] : memref&lt;8x8xi32, #linear8&gt;
    }
  }
  }
  return
}
</code></pre><p>Output</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> <span class=nf>@linearize</span><span class=p>(</span><span class=nv>%arg0</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span><span class=p>,</span>
                <span class=nv>%arg1</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span><span class=p>,</span>
                <span class=nv>%arg2</span><span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span><span class=p>)</span> <span class=p>{</span>
<span class=nv>%c8</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>8</span> <span class=p>:</span> <span class=k>index</span>
<span class=nv>%c0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>0</span> <span class=p>:</span> <span class=k>index</span>
affine<span class=p>.</span>for <span class=nv>%arg3</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%c8</span> <span class=p>{</span>
  affine<span class=p>.</span>for <span class=nv>%arg4</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%c8</span> <span class=p>{</span>
    affine<span class=p>.</span>for <span class=nv>%arg5</span> <span class=p>=</span> <span class=nv>%c0</span> to <span class=nv>%c8</span> <span class=p>{</span>
      <span class=nv>%0</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg0</span><span class=p>[</span><span class=nv>%arg3</span> <span class=p>*</span> <span class=m>8</span> <span class=err>+</span> <span class=nv>%arg5</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span>
      <span class=nv>%1</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg1</span><span class=p>[</span><span class=nv>%arg5</span> <span class=p>*</span> <span class=m>8</span> <span class=err>+</span> <span class=nv>%arg4</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span>
      <span class=nv>%2</span> <span class=p>=</span> affine<span class=p>.</span>load <span class=nv>%arg2</span><span class=p>[</span><span class=nv>%arg3</span> <span class=p>*</span> <span class=m>8</span> <span class=err>+</span> <span class=nv>%arg4</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span>
      <span class=nv>%3</span> <span class=p>=</span> muli <span class=nv>%0</span><span class=p>,</span> <span class=nv>%1</span> <span class=p>:</span> <span class=k>i32</span>
      <span class=nv>%4</span> <span class=p>=</span> addi <span class=nv>%2</span><span class=p>,</span> <span class=nv>%3</span> <span class=p>:</span> <span class=k>i32</span>
      affine<span class=p>.</span>store <span class=nv>%4</span><span class=p>,</span> <span class=nv>%arg2</span><span class=p>[</span><span class=nv>%arg3</span> <span class=p>*</span> <span class=m>8</span> <span class=err>+</span> <span class=nv>%arg4</span><span class=p>]</span> <span class=p>:</span> <span class=kt>memref</span><span class=p>&lt;</span><span class=m>64x</span><span class=k>i32</span><span class=p>&gt;</span>
    <span class=p>}</span>
  <span class=p>}</span>
<span class=p>}</span>
<span class=kt>return</span>

<span class=err>`</span>
<span class=err>#</span><span class=err>#</span><span class=err>#</span> <span class=err>`</span><span class=err>-</span>parallel<span class=err>-</span>loop<span class=err>-</span>collapsing<span class=err>`</span><span class=p>:</span> Collapse parallel loops to use less induction variables

<span class=err>#</span><span class=err>#</span><span class=err>#</span><span class=err>#</span> Options
</code></pre></div><p>-collapsed-indices-0 : Which loop indices to combine 0th loop index
-collapsed-indices-1 : Which loop indices to combine into the position 1 loop index
-collapsed-indices-2 : Which loop indices to combine into the position 2 loop index</p><pre><code>### `-print-cfg-graph`: Print CFG graph per-Region
### `-print-op-graph`: Print op graph per-Region
### `-print-op-stats`: Print statistics of operations
### `-promote-buffers-to-stack`: Promotes heap-based allocations to automatically managed stack-based allocations
This pass implements a simple algorithm to convert heap-based memory
allocations to stack-based ones. It uses a built-in heuristic to decide
whether it makes sense to convert an allocation. Furthermore, dynamic
shaped buffers that are limited by the rank of the tensor can be
converted. They are only transformed if they are considered to be small.

#### Options
</code></pre><p>-max-alloc-size-in-bytes : Maximal size in bytes to promote allocations to stack.
-bitwidth-of-index-type : Bitwidth of the index type. Used for size estimation.
-max-rank-of-allocated-memref : Maximal memref rank to promote dynamic buffers.</p><pre><code>### `-sccp`: Sparse Conditional Constant Propagation
This pass implements a general algorithm for sparse conditional constant
propagation. This algorithm detects values that are known to be constant and
optimistically propagates this throughout the IR. Any values proven to be
constant are replaced, and removed if possible.

This implementation is based on the algorithm described by Wegman and Zadeck
in [“Constant Propagation with Conditional Branches”](https://dl.acm.org/doi/10.1145/103135.103136) (1991).
### `-snapshot-op-locations`: Generate new locations from the current IR
This pass allows for generating new locations from the IR during any stage
of compilation, by snapshotting the IR to a file and using that file to
generate new locations for the operations.

Depending on the value of the `tag` option, different resulting locations
may be generated:

* If unset, the original location of the operation is replaced.

Example:

```mlir
// old:
... loc(&quot;original_source.cpp&quot;:1:1)

// new:
... loc(&quot;snapshot_source.mlir&quot;:10:10)
</code></pre><ul><li>If set, the new location is fused with the original location in the form
of a
<a href=/docs/Diagnostics/#name-location><code>Name Location</code></a>
with the specified tag.</li></ul><p>Example:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=c>// old:
</span><span class=c></span><span class=p>.</span><span class=p>.</span><span class=p>.</span> <span class=kt>loc</span><span class=p>(</span><span class=s>&#34;original_source.cpp&#34;</span><span class=p>:</span><span class=m>1</span><span class=p>:</span><span class=m>1</span><span class=p>)</span>

<span class=c>// new:
</span><span class=c></span><span class=p>.</span><span class=p>.</span><span class=p>.</span> <span class=kt>loc</span><span class=p>(</span>fused<span class=p>[</span><span class=s>&#34;original_source.cpp&#34;</span><span class=p>:</span><span class=m>1</span><span class=p>:</span><span class=m>1</span><span class=p>,</span> <span class=s>&#34;snapshot&#34;</span><span class=p>(</span><span class=s>&#34;snapshot_source.mlir&#34;</span><span class=p>:</span><span class=m>10</span><span class=p>:</span><span class=m>10</span><span class=p>)</span><span class=p>]</span><span class=p>)</span>
</code></pre></div><h4 id=options-2>Options&nbsp;<a class=headline-hash href=#options-2>¶</a></h4><pre><code>-filename : The filename to print the generated IR
-tag      : A tag to use when fusing the new locations with the original. If unset, the locations are replaced.
</code></pre><h3 id=-strip-debuginfo-strip-debug-info-from-all-operations><code>-strip-debuginfo</code>: Strip debug info from all operations&nbsp;<a class=headline-hash href=#-strip-debuginfo-strip-debug-info-from-all-operations>¶</a></h3><p>This pass strips the IR of any location information, by replacing all
operation locations with
<a href=/docs/Diagnostics/#unknown-location><code>unknown</code></a>
.</p><h3 id=-symbol-dce-eliminate-dead-symbols><code>-symbol-dce</code>: Eliminate dead symbols&nbsp;<a class=headline-hash href=#-symbol-dce-eliminate-dead-symbols>¶</a></h3><p>This pass deletes all symbols that are found to be unreachable. This is done
by computing the set of operations that are known to be live, propagating
that liveness to other symbols, and then deleting all symbols that are not
within this live set. Live symbols are those that have a
<a href=/docs/SymbolsAndSymbolTables/#symbol-visibility>visibility</a>
that extends
beyond the IR, e.g. <code>public</code>, or those that are referenced by live symbols
or other non-Symbol operations.</p><p>For example, consider the following input:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> private <span class=nf>@dead_private_function</span><span class=p>(</span><span class=p>)</span>
<span class=kt>func</span> private <span class=nf>@live_private_function</span><span class=p>(</span><span class=p>)</span>

<span class=c>// Note: The `public` isn&#39;t necessary here, as this is the default.
</span><span class=c></span><span class=kt>func</span> public <span class=nf>@public_function</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
  <span class=s>&#34;foo.return&#34;</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span><span class=nl>uses =</span> <span class=p>[</span><span class=nf>@live_private_function</span><span class=p>]</span><span class=p>}</span> <span class=p>:</span> <span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></div><p>A known live function, <code>public_function</code>, contains a reference to an
otherwise non-live function <code>live_private_function</code>. After running
<code>symbol-dce</code>, only these two symbols should remain, as the final symbol
<code>dead_private_function</code> is not visible outside of the current IR and there
are no links to known-live operations. After running, we get the expected:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=kt>func</span> private <span class=nf>@live_private_function</span><span class=p>(</span><span class=p>)</span>

<span class=kt>func</span> public <span class=nf>@public_function</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span>
  <span class=s>&#34;foo.return&#34;</span><span class=p>(</span><span class=p>)</span> <span class=p>{</span><span class=nl>uses =</span> <span class=p>[</span><span class=nf>@live_private_function</span><span class=p>]</span><span class=p>}</span> <span class=p>:</span> <span class=p>(</span><span class=p>)</span> <span class=p>-&gt;</span> <span class=p>(</span><span class=p>)</span>
<span class=p>}</span>
</code></pre></div><p>See
<a href=/docs/SymbolsAndSymbolTables/>Symbols and SymbolTables</a>
for more
information on <code>Symbols</code>.</p><h2 id=conversion-passes>Conversion Passes&nbsp;<a class=headline-hash href=#conversion-passes>¶</a></h2><h3 id=-convert-affine-for-to-gpu-convert-top-level-affinefor-ops-to-gpu-kernels><code>-convert-affine-for-to-gpu</code>: Convert top-level AffineFor Ops to GPU kernels&nbsp;<a class=headline-hash href=#-convert-affine-for-to-gpu-convert-top-level-affinefor-ops-to-gpu-kernels>¶</a></h3><h4 id=options-3>Options&nbsp;<a class=headline-hash href=#options-3>¶</a></h4><pre><code>-gpu-block-dims  : Number of GPU block dimensions for mapping
-gpu-thread-dims : Number of GPU thread dimensions for mapping
</code></pre><h3 id=-convert-async-to-llvm-convert-the-operations-from-the-async-dialect-into-the-llvm-dialect><code>-convert-async-to-llvm</code>: Convert the operations from the async dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-async-to-llvm-convert-the-operations-from-the-async-dialect-into-the-llvm-dialect>¶</a></h3><p>Convert <code>async.execute</code> operations to LLVM coroutines and use async runtime
API to execute them.</p><h3 id=-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call><code>-convert-gpu-launch-to-vulkan-launch</code>: Convert gpu.launch_func to vulkanLaunch external call&nbsp;<a class=headline-hash href=#-convert-gpu-launch-to-vulkan-launch-convert-gpulaunch_func-to-vulkanlaunch-external-call>¶</a></h3><h3 id=-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations><code>-convert-gpu-to-nvvm</code>: Generate NVVM operations for gpu operations&nbsp;<a class=headline-hash href=#-convert-gpu-to-nvvm-generate-nvvm-operations-for-gpu-operations>¶</a></h3><h4 id=options-4>Options&nbsp;<a class=headline-hash href=#options-4>¶</a></h4><pre><code>-index-bitwidth : Bitwidth of the index type, 0 to use size of machine word
</code></pre><h3 id=-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations><code>-convert-gpu-to-rocdl</code>: Generate ROCDL operations for gpu operations&nbsp;<a class=headline-hash href=#-convert-gpu-to-rocdl-generate-rocdl-operations-for-gpu-operations>¶</a></h3><h4 id=options-5>Options&nbsp;<a class=headline-hash href=#options-5>¶</a></h4><pre><code>-index-bitwidth : Bitwidth of the index type, 0 to use size of machine word
</code></pre><h3 id=-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect><code>-convert-gpu-to-spirv</code>: Convert GPU dialect to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-gpu-to-spirv-convert-gpu-dialect-to-spir-v-dialect>¶</a></h3><h3 id=-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect><code>-convert-linalg-to-llvm</code>: Convert the operations from the linalg dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-linalg-to-llvm-convert-the-operations-from-the-linalg-dialect-into-the-llvm-dialect>¶</a></h3><h3 id=-convert-linalg-to-spirv-convert-linalg-ops-to-spir-v-ops><code>-convert-linalg-to-spirv</code>: Convert Linalg ops to SPIR-V ops&nbsp;<a class=headline-hash href=#-convert-linalg-to-spirv-convert-linalg-ops-to-spir-v-ops>¶</a></h3><h3 id=-convert-linalg-to-std-convert-the-operations-from-the-linalg-dialect-into-the-standard-dialect><code>-convert-linalg-to-std</code>: Convert the operations from the linalg dialect into the Standard dialect&nbsp;<a class=headline-hash href=#-convert-linalg-to-std-convert-the-operations-from-the-linalg-dialect-into-the-standard-dialect>¶</a></h3><h3 id=-convert-openmp-to-llvm-convert-the-openmp-ops-to-openmp-ops-with-llvm-dialect><code>-convert-openmp-to-llvm</code>: Convert the OpenMP ops to OpenMP ops with LLVM dialect&nbsp;<a class=headline-hash href=#-convert-openmp-to-llvm-convert-the-openmp-ops-to-openmp-ops-with-llvm-dialect>¶</a></h3><h3 id=-convert-parallel-loops-to-gpu-convert-mapped-scfparallel-ops-to-gpu-launch-operations><code>-convert-parallel-loops-to-gpu</code>: Convert mapped scf.parallel ops to gpu launch operations&nbsp;<a class=headline-hash href=#-convert-parallel-loops-to-gpu-convert-mapped-scfparallel-ops-to-gpu-launch-operations>¶</a></h3><h3 id=-convert-pdl-to-pdl-interp-convert-pdl-ops-to-pdl-interpreter-ops><code>-convert-pdl-to-pdl-interp</code>: Convert PDL ops to PDL interpreter ops&nbsp;<a class=headline-hash href=#-convert-pdl-to-pdl-interp-convert-pdl-ops-to-pdl-interpreter-ops>¶</a></h3><h3 id=-convert-scf-to-openmp-convert-scf-parallel-loop-to-openmp-parallel--workshare-constructs><code>-convert-scf-to-openmp</code>: Convert SCF parallel loop to OpenMP parallel + workshare constructs.&nbsp;<a class=headline-hash href=#-convert-scf-to-openmp-convert-scf-parallel-loop-to-openmp-parallel--workshare-constructs>¶</a></h3><h3 id=-convert-scf-to-std-convert-scf-dialect-to-standard-dialect-replacing-structured-control-flow-with-a-cfg><code>-convert-scf-to-std</code>: Convert SCF dialect to Standard dialect, replacing structured control flow with a CFG&nbsp;<a class=headline-hash href=#-convert-scf-to-std-convert-scf-dialect-to-standard-dialect-replacing-structured-control-flow-with-a-cfg>¶</a></h3><h3 id=-convert-shape-constraints-convert-shape-constraint-operations-to-the-standard-dialect><code>-convert-shape-constraints</code>: Convert shape constraint operations to the standard dialect&nbsp;<a class=headline-hash href=#-convert-shape-constraints-convert-shape-constraint-operations-to-the-standard-dialect>¶</a></h3><p>This pass eliminates shape constraints from the program, converting them to
eager (side-effecting) error handling code.</p><p>This pass is separate from the regular convert-shape-to-standard, despite
converting between the same dialects, because converting shape constraints
can happen at a different part of the program than general shape
computation lowering.</p><h3 id=-convert-shape-to-std-convert-operations-from-the-shape-dialect-into-the-standard-dialect><code>-convert-shape-to-std</code>: Convert operations from the shape dialect into the standard dialect&nbsp;<a class=headline-hash href=#-convert-shape-to-std-convert-operations-from-the-shape-dialect-into-the-standard-dialect>¶</a></h3><h3 id=-convert-spirv-to-llvm-convert-spir-v-dialect-to-llvm-dialect><code>-convert-spirv-to-llvm</code>: Convert SPIR-V dialect to LLVM dialect&nbsp;<a class=headline-hash href=#-convert-spirv-to-llvm-convert-spir-v-dialect-to-llvm-dialect>¶</a></h3><h3 id=-convert-std-to-llvm-convert-scalar-and-vector-operations-from-the-standard-to-the-llvm-dialect><code>-convert-std-to-llvm</code>: Convert scalar and vector operations from the Standard to the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-std-to-llvm-convert-scalar-and-vector-operations-from-the-standard-to-the-llvm-dialect>¶</a></h3><p>Convert standard operations into the LLVM IR dialect operations.</p><h4 id=input-invariant>Input invariant&nbsp;<a class=headline-hash href=#input-invariant>¶</a></h4><ul><li>operations including: arithmetic on integers and floats, constants,
direct calls, returns and branches;</li><li>no <code>tensor</code> types;</li><li>all <code>vector</code> are one-dimensional;</li><li>all blocks are reachable by following the successors of the first basic
block;</li></ul><p>If other operations are present and their results are required by the LLVM
IR dialect operations, the pass will fail. Any LLVM IR operations or types
already present in the IR will be kept as is.</p><h4 id=output-ir>Output IR&nbsp;<a class=headline-hash href=#output-ir>¶</a></h4><p>Functions converted to LLVM IR. Function arguments types are converted
one-to-one. Function results are converted one-to-one and, in case more than
1 value is returned, packed into an LLVM IR struct type. Function calls and
returns are updated accordingly. Block argument types are updated to use
LLVM IR types.</p><h4 id=options-6>Options&nbsp;<a class=headline-hash href=#options-6>¶</a></h4><pre><code>-use-aligned-alloc             : Use aligned_alloc in place of malloc for heap allocations
-use-bare-ptr-memref-call-conv : Replace FuncOp's MemRef arguments with bare pointers to the MemRef element types
-emit-c-wrappers               : Emit wrappers for C-compatible pointer-to-struct memref descriptors
-index-bitwidth                : Bitwidth of the index type, 0 to use size of machine word
-data-layout                   : String description (LLVM format) of the data layout that is expected on the produced module
</code></pre><h3 id=-convert-std-to-spirv-convert-standard-ops-to-spir-v-dialect><code>-convert-std-to-spirv</code>: Convert Standard Ops to SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-std-to-spirv-convert-standard-ops-to-spir-v-dialect>¶</a></h3><h3 id=-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect><code>-convert-vector-to-llvm</code>: Lower the operations from the vector dialect into the LLVM dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-llvm-lower-the-operations-from-the-vector-dialect-into-the-llvm-dialect>¶</a></h3><p>Convert operations from the vector dialect into the LLVM IR dialect
operations. The lowering pass provides several options to control
the kinds of optimizations that are allowed. It also provides options
that enable the use of one or more architectural-specific dialects
(AVX512, ArmNeon, ArmSVE, etc.) in combination with the
architectural-neutral vector dialect lowering.</p><h4 id=options-7>Options&nbsp;<a class=headline-hash href=#options-7>¶</a></h4><pre><code>-reassociate-fp-reductions  : Allows llvm to reassociate floating-point reductions for speed
-enable-index-optimizations : Allows compiler to assume indices fit in 32-bit if that yields faster code
-enable-avx512              : Enables the use of AVX512 dialect while lowering the vector dialect.
-enable-arm-neon            : Enables the use of ArmNeon dialect while lowering the vector dialect.
-enable-arm-sve             : Enables the use of ArmSVE dialect while lowering the vector dialect.
</code></pre><h3 id=-convert-vector-to-rocdl-lower-the-operations-from-the-vector-dialect-into-the-rocdl-dialect><code>-convert-vector-to-rocdl</code>: Lower the operations from the vector dialect into the ROCDL dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-rocdl-lower-the-operations-from-the-vector-dialect-into-the-rocdl-dialect>¶</a></h3><h3 id=-convert-vector-to-scf-lower-the-operations-from-the-vector-dialect-into-the-scf-dialect><code>-convert-vector-to-scf</code>: Lower the operations from the vector dialect into the SCF dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-scf-lower-the-operations-from-the-vector-dialect-into-the-scf-dialect>¶</a></h3><h4 id=options-8>Options&nbsp;<a class=headline-hash href=#options-8>¶</a></h4><pre><code>-full-unroll : Perform full unrolling when converting vector transfers to SCF
</code></pre><h3 id=-convert-vector-to-spirv-lower-the-operations-from-the-vector-dialect-into-the-spir-v-dialect><code>-convert-vector-to-spirv</code>: Lower the operations from the vector dialect into the SPIR-V dialect&nbsp;<a class=headline-hash href=#-convert-vector-to-spirv-lower-the-operations-from-the-vector-dialect-into-the-spir-v-dialect>¶</a></h3><h3 id=-gpu-to-llvm-convert-gpu-dialect-to-llvm-dialect-with-gpu-runtime-calls><code>-gpu-to-llvm</code>: Convert GPU dialect to LLVM dialect with GPU runtime calls&nbsp;<a class=headline-hash href=#-gpu-to-llvm-convert-gpu-dialect-to-llvm-dialect-with-gpu-runtime-calls>¶</a></h3><h4 id=options-9>Options&nbsp;<a class=headline-hash href=#options-9>¶</a></h4><pre><code>-gpu-binary-annotation : Annotation attribute string for GPU binary
</code></pre><h3 id=-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls><code>-launch-func-to-vulkan</code>: Convert vulkanLaunch external call to Vulkan runtime external calls&nbsp;<a class=headline-hash href=#-launch-func-to-vulkan-convert-vulkanlaunch-external-call-to-vulkan-runtime-external-calls>¶</a></h3><h3 id=-legalize-std-for-spirv-legalize-standard-ops-for-spir-v-lowering><code>-legalize-std-for-spirv</code>: Legalize standard ops for SPIR-V lowering&nbsp;<a class=headline-hash href=#-legalize-std-for-spirv-legalize-standard-ops-for-spir-v-lowering>¶</a></h3><h3 id=-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-scf-operations><code>-lower-affine</code>: Lower Affine operations to a combination of Standard and SCF operations&nbsp;<a class=headline-hash href=#-lower-affine-lower-affine-operations-to-a-combination-of-standard-and-scf-operations>¶</a></h3><p>Convert operations from the affine dialect into operations from the SCF and
standard dialects.</p><p><code>affine.for</code> operations are converted to <code>scf.for</code> operations that are free
of certain structural restrictions (on their bounds and step). <code>affine.if</code>
is similarly converted to the <code>scf.if</code> operation. <code>affine.apply</code> operations
are converted into sequences of primitive arithmetic operations from the
standard dialect that have the same effect, using operands of the <code>index</code>
type. Consequently, named maps and sets thare are no longer in use may be
removed from the module.</p><p>For example, <code>%r = affine.apply affine_map&lt;(d0, d1)[s0] -> (d0 + 2*d1 + s0)>(%d0, %d1)[%s0]</code>
can be converted into:</p><div class=highlight><pre class=chroma><code class=language-mlir data-lang=mlir><span class=nv>%d0</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%d1</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%s0</span> <span class=p>=</span> <span class=p>&lt;</span><span class=p>.</span><span class=p>.</span><span class=p>.</span><span class=p>&gt;</span>
<span class=nv>%0</span> <span class=p>=</span> <span class=kt>constant</span> <span class=m>2</span> <span class=p>:</span> <span class=k>index</span>
<span class=nv>%1</span> <span class=p>=</span> muli <span class=nv>%0</span><span class=p>,</span> <span class=nv>%d1</span>
<span class=nv>%2</span> <span class=p>=</span> addi <span class=nv>%d0</span><span class=p>,</span> <span class=nv>%1</span>
<span class=nv>%r</span> <span class=p>=</span> addi <span class=nv>%2</span><span class=p>,</span> <span class=nv>%s0</span>
</code></pre></div><h4 id=input-invariant-1>Input invariant&nbsp;<a class=headline-hash href=#input-invariant-1>¶</a></h4><ul><li>no <code>Tensor</code> types;</li></ul><p>These restrictions may be lifted in the future.</p><h4 id=output-ir-1>Output IR&nbsp;<a class=headline-hash href=#output-ir-1>¶</a></h4><p>Functions with <code>affine.for</code> and <code>affine.if</code> operations eliminated. These
functions may contain operations from the Standard dialect in addition to
those already present before the pass.</p><h4 id=invariants>Invariants&nbsp;<a class=headline-hash href=#invariants>¶</a></h4><ul><li>Functions without a body are not modified.</li><li>The semantics of the other functions is preserved.</li><li>Individual operations other than those mentioned above are not modified
if they do not depend on the loop iterator value or on the result of
<code>affine.apply</code>.</li></ul><h3 id=-lower-host-to-llvm-lowers-the-host-module-code-and-gpulaunch_func-to-llvm><code>-lower-host-to-llvm</code>: Lowers the host module code and <code>gpu.launch_func</code> to LLVM&nbsp;<a class=headline-hash href=#-lower-host-to-llvm-lowers-the-host-module-code-and-gpulaunch_func-to-llvm>¶</a></h3><h2 id=async-dialect-passes><code>async</code> Dialect Passes&nbsp;<a class=headline-hash href=#async-dialect-passes>¶</a></h2><h3 id=-async-parallel-for-convert-scfparallel-operations-to-multiple-async-regions-executed-concurrently-for-non-overlapping-iteration-ranges><code>-async-parallel-for</code>: Convert scf.parallel operations to multiple async regions executed concurrently for non-overlapping iteration ranges&nbsp;<a class=headline-hash href=#-async-parallel-for-convert-scfparallel-operations-to-multiple-async-regions-executed-concurrently-for-non-overlapping-iteration-ranges>¶</a></h3><h4 id=options-10>Options&nbsp;<a class=headline-hash href=#options-10>¶</a></h4><pre><code>-num-concurrent-async-execute : The number of async.execute operations that will be used for concurrent loop execution.
</code></pre><h3 id=-async-ref-counting-automatic-reference-counting-for-async-dialect-data-types><code>-async-ref-counting</code>: Automatic reference counting for Async dialect data types&nbsp;<a class=headline-hash href=#-async-ref-counting-automatic-reference-counting-for-async-dialect-data-types>¶</a></h3><h3 id=-async-ref-counting-optimization-optimize-automatic-reference-counting-operations-for-theasync-dialect-by-removing-redundant-operations><code>-async-ref-counting-optimization</code>: Optimize automatic reference counting operations for theAsync dialect by removing redundant operations&nbsp;<a class=headline-hash href=#-async-ref-counting-optimization-optimize-automatic-reference-counting-operations-for-theasync-dialect-by-removing-redundant-operations>¶</a></h3><h2 id=affine-dialect-passes><code>affine</code> Dialect Passes&nbsp;<a class=headline-hash href=#affine-dialect-passes>¶</a></h2><h3 id=-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations><code>-affine-data-copy-generate</code>: Generate explicit copying for affine memory operations&nbsp;<a class=headline-hash href=#-affine-data-copy-generate-generate-explicit-copying-for-affine-memory-operations>¶</a></h3><h4 id=options-11>Options&nbsp;<a class=headline-hash href=#options-11>¶</a></h4><pre><code>-fast-mem-capacity          : Set fast memory space capacity in KiB (default: unlimited)
-fast-mem-space             : Fast memory space identifier for copy generation (default: 1)
-generate-dma               : Generate DMA instead of point-wise copy
-min-dma-transfer           : Minimum DMA transfer size supported by the target in bytes
-slow-mem-space             : Slow memory space identifier for copy generation (default: 0)
-skip-non-unit-stride-loops : Testing purposes: avoid non-unit stride loop choice depths for copy placement
-tag-mem-space              : Tag memory space identifier for copy generation (default: 0)
</code></pre><h3 id=-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops><code>-affine-loop-invariant-code-motion</code>: Hoist loop invariant instructions outside of affine loops&nbsp;<a class=headline-hash href=#-affine-loop-invariant-code-motion-hoist-loop-invariant-instructions-outside-of-affine-loops>¶</a></h3><h3 id=-affine-loop-normalize-apply-normalization-transformations-to-affine-loop-like-ops><code>-affine-loop-normalize</code>: Apply normalization transformations to affine loop-like ops&nbsp;<a class=headline-hash href=#-affine-loop-normalize-apply-normalization-transformations-to-affine-loop-like-ops>¶</a></h3><h3 id=-affine-loop-tile-tile-affine-loop-nests><code>-affine-loop-tile</code>: Tile affine loop nests&nbsp;<a class=headline-hash href=#-affine-loop-tile-tile-affine-loop-nests>¶</a></h3><h4 id=options-12>Options&nbsp;<a class=headline-hash href=#options-12>¶</a></h4><pre><code>-cache-size : Set size of cache to tile for in KiB
-separate   : Separate full and partial tiles
-tile-size  : Use this tile size for all loops
-tile-sizes : List of tile sizes for each perfect nest (overridden by -tile-size)
</code></pre><h3 id=-affine-loop-unroll-unroll-affine-loops><code>-affine-loop-unroll</code>: Unroll affine loops&nbsp;<a class=headline-hash href=#-affine-loop-unroll-unroll-affine-loops>¶</a></h3><h4 id=options-13>Options&nbsp;<a class=headline-hash href=#options-13>¶</a></h4><pre><code>-unroll-factor         : Use this unroll factor for all loops being unrolled
-unroll-up-to-factor   : Allow unrolling up to the factor specified
-unroll-full           : Fully unroll loops
-unroll-num-reps       : Unroll innermost loops repeatedly this many times
-unroll-full-threshold : Unroll all loops with trip count less than or equal to this
</code></pre><h3 id=-affine-loop-unroll-jam-unroll-and-jam-affine-loops><code>-affine-loop-unroll-jam</code>: Unroll and jam affine loops&nbsp;<a class=headline-hash href=#-affine-loop-unroll-jam-unroll-and-jam-affine-loops>¶</a></h3><h4 id=options-14>Options&nbsp;<a class=headline-hash href=#options-14>¶</a></h4><pre><code>-unroll-jam-factor : Use this unroll jam factor for all loops (default 4)
</code></pre><h3 id=-affine-parallelize-convert-affinefor-ops-into-1-d-affineparallel><code>-affine-parallelize</code>: Convert affine.for ops into 1-D affine.parallel&nbsp;<a class=headline-hash href=#-affine-parallelize-convert-affinefor-ops-into-1-d-affineparallel>¶</a></h3><h4 id=options-15>Options&nbsp;<a class=headline-hash href=#options-15>¶</a></h4><pre><code>-max-nested : Maximum number of nested parallel loops to produce. Defaults to unlimited (UINT_MAX).
</code></pre><h3 id=-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction><code>-affine-super-vectorize</code>: Vectorize to a target independent n-D vector abstraction&nbsp;<a class=headline-hash href=#-affine-super-vectorize-vectorize-to-a-target-independent-n-d-vector-abstraction>¶</a></h3><h4 id=options-16>Options&nbsp;<a class=headline-hash href=#options-16>¶</a></h4><pre><code>-virtual-vector-size  : Specify an n-D virtual vector size for vectorization
-test-fastest-varying : Specify a 1-D, 2-D or 3-D pattern of fastest varying memory dimensions to match. See defaultPatterns in Vectorize.cpp for a description and examples. This is used for testing purposes
</code></pre><h3 id=-simplify-affine-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs><code>-simplify-affine-structures</code>: Simplify affine expressions in maps/sets and normalize memrefs&nbsp;<a class=headline-hash href=#-simplify-affine-structures-simplify-affine-expressions-in-mapssets-and-normalize-memrefs>¶</a></h3><h2 id=gpu-dialect-passes><code>gpu</code> Dialect Passes&nbsp;<a class=headline-hash href=#gpu-dialect-passes>¶</a></h2><h3 id=-gpu-async-region-make-gpu-ops-async><code>-gpu-async-region</code>: Make GPU ops async&nbsp;<a class=headline-hash href=#-gpu-async-region-make-gpu-ops-async>¶</a></h3><h3 id=-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions><code>-gpu-kernel-outlining</code>: Outline gpu.launch bodies to kernel functions&nbsp;<a class=headline-hash href=#-gpu-kernel-outlining-outline-gpulaunch-bodies-to-kernel-functions>¶</a></h3><h2 id=linalg-dialect-passes><code>linalg</code> Dialect Passes&nbsp;<a class=headline-hash href=#linalg-dialect-passes>¶</a></h2><h3 id=-convert-elementwise-to-linalg-convert-elementwisemappable-ops-to-linalg><code>-convert-elementwise-to-linalg</code>: Convert ElementwiseMappable ops to linalg&nbsp;<a class=headline-hash href=#-convert-elementwise-to-linalg-convert-elementwisemappable-ops-to-linalg>¶</a></h3><p>Convert ops with the <code>ElementwiseMappable</code> trait to linalg parallel loops.</p><p>This pass only converts ops that operate on ranked tensors.</p><h3 id=-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops><code>-convert-linalg-to-affine-loops</code>: Lower the operations from the linalg dialect into affine loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-affine-loops-lower-the-operations-from-the-linalg-dialect-into-affine-loops>¶</a></h3><h3 id=-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops><code>-convert-linalg-to-loops</code>: Lower the operations from the linalg dialect into loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-loops-lower-the-operations-from-the-linalg-dialect-into-loops>¶</a></h3><h3 id=-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops><code>-convert-linalg-to-parallel-loops</code>: Lower the operations from the linalg dialect into parallel loops&nbsp;<a class=headline-hash href=#-convert-linalg-to-parallel-loops-lower-the-operations-from-the-linalg-dialect-into-parallel-loops>¶</a></h3><h3 id=-linalg-bufferize-bufferize-the-linalg-dialect><code>-linalg-bufferize</code>: Bufferize the linalg dialect&nbsp;<a class=headline-hash href=#-linalg-bufferize-bufferize-the-linalg-dialect>¶</a></h3><h3 id=-linalg-fold-reshape-ops-by-linearization-fold-tensorreshapeops-with-genericindexed-generic-ops-by-linearization><code>-linalg-fold-reshape-ops-by-linearization</code>: Fold TensorReshapeOps with generic/indexed generic ops by linearization&nbsp;<a class=headline-hash href=#-linalg-fold-reshape-ops-by-linearization-fold-tensorreshapeops-with-genericindexed-generic-ops-by-linearization>¶</a></h3><h3 id=-linalg-fold-unit-extent-dims-remove-unit-extent-dimension-in-linalg-ops-on-tensors><code>-linalg-fold-unit-extent-dims</code>: Remove unit-extent dimension in Linalg ops on tensors&nbsp;<a class=headline-hash href=#-linalg-fold-unit-extent-dims-remove-unit-extent-dimension-in-linalg-ops-on-tensors>¶</a></h3><h4 id=options-17>Options&nbsp;<a class=headline-hash href=#options-17>¶</a></h4><pre><code>-fold-one-trip-loops-only : Only folds the one-trip loops from Linalg ops on tensors (for testing purposes only)
</code></pre><h3 id=-linalg-fusion-for-tensor-ops-fuse-operations-on-rankedtensortype-in-linalg-dialect><code>-linalg-fusion-for-tensor-ops</code>: Fuse operations on RankedTensorType in linalg dialect&nbsp;<a class=headline-hash href=#-linalg-fusion-for-tensor-ops-fuse-operations-on-rankedtensortype-in-linalg-dialect>¶</a></h3><h3 id=-linalg-generalize-named-ops-convert-named-ops-into-generic-ops><code>-linalg-generalize-named-ops</code>: Convert named ops into generic ops&nbsp;<a class=headline-hash href=#-linalg-generalize-named-ops-convert-named-ops-into-generic-ops>¶</a></h3><h3 id=-linalg-promote-subviews-promote-subview-ops-to-local-buffers><code>-linalg-promote-subviews</code>: Promote subview ops to local buffers&nbsp;<a class=headline-hash href=#-linalg-promote-subviews-promote-subview-ops-to-local-buffers>¶</a></h3><h4 id=options-18>Options&nbsp;<a class=headline-hash href=#options-18>¶</a></h4><pre><code>-test-promote-dynamic : Test generation of dynamic promoted buffers
-test-use-alloca      : Test generation of alloca'ed buffers.
</code></pre><h3 id=-linalg-tile-tile-operations-in-the-linalg-dialect><code>-linalg-tile</code>: Tile operations in the linalg dialect&nbsp;<a class=headline-hash href=#-linalg-tile-tile-operations-in-the-linalg-dialect>¶</a></h3><h4 id=options-19>Options&nbsp;<a class=headline-hash href=#options-19>¶</a></h4><pre><code>-linalg-tile-sizes : Test generation of dynamic promoted buffers
</code></pre><h3 id=-linalg-tile-to-parallel-loops-tile-operations-in-the-linalg-dialect-to-parallel-loops><code>-linalg-tile-to-parallel-loops</code>: Tile operations in the linalg dialect to parallel loops&nbsp;<a class=headline-hash href=#-linalg-tile-to-parallel-loops-tile-operations-in-the-linalg-dialect-to-parallel-loops>¶</a></h3><h4 id=options-20>Options&nbsp;<a class=headline-hash href=#options-20>¶</a></h4><pre><code>-linalg-tile-sizes : Test generation of dynamic promoted buffers
</code></pre><h2 id=llvm-dialect-passes><code>llvm</code> Dialect Passes&nbsp;<a class=headline-hash href=#llvm-dialect-passes>¶</a></h2><h3 id=-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir><code>-llvm-legalize-for-export</code>: Legalize LLVM dialect to be convertible to LLVM IR&nbsp;<a class=headline-hash href=#-llvm-legalize-for-export-legalize-llvm-dialect-to-be-convertible-to-llvm-ir>¶</a></h3><h2 id=quant-dialect-passes><code>quant</code> Dialect Passes&nbsp;<a class=headline-hash href=#quant-dialect-passes>¶</a></h2><h3 id=-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values><code>-quant-convert-const</code>: Converts constants followed by qbarrier to actual quantized values&nbsp;<a class=headline-hash href=#-quant-convert-const-converts-constants-followed-by-qbarrier-to-actual-quantized-values>¶</a></h3><h3 id=-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts><code>-quant-convert-simulated-quantization</code>: Converts training-time simulated quantization ops to corresponding quantize/dequantize casts&nbsp;<a class=headline-hash href=#-quant-convert-simulated-quantization-converts-training-time-simulated-quantization-ops-to-corresponding-quantizedequantize-casts>¶</a></h3><h2 id=reducer-passes>Reducer Passes&nbsp;<a class=headline-hash href=#reducer-passes>¶</a></h2><h3 id=-opt-reduction-pass-a-reduction-pass-wrapper-for-optimization-passes><code>-opt-reduction-pass</code>: A reduction pass wrapper for optimization passes&nbsp;<a class=headline-hash href=#-opt-reduction-pass-a-reduction-pass-wrapper-for-optimization-passes>¶</a></h3><h3 id=-reduction-tree-a-general-reduction-tree-pass-for-the-mlir-reduce-tool><code>-reduction-tree</code>: A general reduction tree pass for the MLIR Reduce Tool&nbsp;<a class=headline-hash href=#-reduction-tree-a-general-reduction-tree-pass-for-the-mlir-reduce-tool>¶</a></h3><h2 id=scf-dialect-passes><code>scf</code> Dialect Passes&nbsp;<a class=headline-hash href=#scf-dialect-passes>¶</a></h2><h3 id=-for-loop-specialization-specialize-for-loops-for-vectorization><code>-for-loop-specialization</code>: Specialize <code>for</code> loops for vectorization&nbsp;<a class=headline-hash href=#-for-loop-specialization-specialize-for-loops-for-vectorization>¶</a></h3><h3 id=-parallel-loop-fusion-fuse-adjacent-parallel-loops><code>-parallel-loop-fusion</code>: Fuse adjacent parallel loops&nbsp;<a class=headline-hash href=#-parallel-loop-fusion-fuse-adjacent-parallel-loops>¶</a></h3><h3 id=-parallel-loop-specialization-specialize-parallel-loops-for-vectorization><code>-parallel-loop-specialization</code>: Specialize parallel loops for vectorization&nbsp;<a class=headline-hash href=#-parallel-loop-specialization-specialize-parallel-loops-for-vectorization>¶</a></h3><h3 id=-parallel-loop-tiling-tile-parallel-loops><code>-parallel-loop-tiling</code>: Tile parallel loops&nbsp;<a class=headline-hash href=#-parallel-loop-tiling-tile-parallel-loops>¶</a></h3><h4 id=options-21>Options&nbsp;<a class=headline-hash href=#options-21>¶</a></h4><pre><code>-parallel-loop-tile-sizes : Factors to tile parallel loops by
</code></pre><h3 id=-scf-bufferize-bufferize-the-scf-dialect><code>-scf-bufferize</code>: Bufferize the scf dialect.&nbsp;<a class=headline-hash href=#-scf-bufferize-bufferize-the-scf-dialect>¶</a></h3><h2 id=shape-dialect-passes><code>shape</code> Dialect Passes&nbsp;<a class=headline-hash href=#shape-dialect-passes>¶</a></h2><h3 id=-remove-shape-constraints-replace-all-cstr_-ops-with-a-true-witness><code>-remove-shape-constraints</code>: Replace all cstr_ ops with a true witness&nbsp;<a class=headline-hash href=#-remove-shape-constraints-replace-all-cstr_-ops-with-a-true-witness>¶</a></h3><h3 id=-shape-bufferize-bufferize-the-shape-dialect><code>-shape-bufferize</code>: Bufferize the shape dialect.&nbsp;<a class=headline-hash href=#-shape-bufferize-bufferize-the-shape-dialect>¶</a></h3><h3 id=-shape-to-shape-lowering-legalize-shape-dialect-to-be-convertible-to-standard><code>-shape-to-shape-lowering</code>: Legalize Shape dialect to be convertible to Standard&nbsp;<a class=headline-hash href=#-shape-to-shape-lowering-legalize-shape-dialect-to-be-convertible-to-standard>¶</a></h3><h2 id=spv-dialect-passes><code>spv</code> Dialect Passes&nbsp;<a class=headline-hash href=#spv-dialect-passes>¶</a></h2><h3 id=-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info><code>-decorate-spirv-composite-type-layout</code>: Decorate SPIR-V composite type with layout info&nbsp;<a class=headline-hash href=#-decorate-spirv-composite-type-layout-decorate-spir-v-composite-type-with-layout-info>¶</a></h3><h3 id=-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info><code>-spirv-lower-abi-attrs</code>: Decorate SPIR-V composite type with layout info&nbsp;<a class=headline-hash href=#-spirv-lower-abi-attrs-decorate-spir-v-composite-type-with-layout-info>¶</a></h3><h3 id=-spirv-rewrite-inserts-rewrite-sequential-chains-of-spvcompositeinsert-operations-into-spvcompositeconstruct-operations><code>-spirv-rewrite-inserts</code>: Rewrite sequential chains of spv.CompositeInsert operations into spv.CompositeConstruct operations&nbsp;<a class=headline-hash href=#-spirv-rewrite-inserts-rewrite-sequential-chains-of-spvcompositeinsert-operations-into-spvcompositeconstruct-operations>¶</a></h3><h3 id=-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops><code>-spirv-update-vce</code>: Deduce and attach minimal (version, capabilities, extensions) requirements to spv.module ops&nbsp;<a class=headline-hash href=#-spirv-update-vce-deduce-and-attach-minimal-version-capabilities-extensions-requirements-to-spvmodule-ops>¶</a></h3><h2 id=standard-dialect-passes><code>standard</code> Dialect Passes&nbsp;<a class=headline-hash href=#standard-dialect-passes>¶</a></h2><h3 id=-func-bufferize-bufferize-funccallreturn-ops><code>-func-bufferize</code>: Bufferize func/call/return ops&nbsp;<a class=headline-hash href=#-func-bufferize-bufferize-funccallreturn-ops>¶</a></h3><p>A bufferize pass that bufferizes std.func and std.call ops.</p><p>Because this pass updates std.func ops, it must be a module pass. It is
useful to keep this pass separate from other bufferizations so that the
other ones can be run at function-level in parallel.</p><p>This pass must be done atomically because it changes func op signatures,
which requires atomically updating calls as well throughout the entire
module.</p><p>This pass also changes the type of block arguments, which requires that all
successor arguments of predecessors be converted. This is achieved by
rewriting terminators based on the information provided by the
<code>BranchOpInterface</code>.
As this pass rewrites function operations, it also rewrites the
corresponding return operations. Other return-like operations that
implement the <code>ReturnLike</code> trait are not rewritten in general, as they
require that the correspondign parent operation is also rewritten.
Finally, this pass fails for unknown terminators, as we cannot decide
whether they need rewriting.</p><h3 id=-std-bufferize-bufferize-the-std-dialect><code>-std-bufferize</code>: Bufferize the std dialect&nbsp;<a class=headline-hash href=#-std-bufferize-bufferize-the-std-dialect>¶</a></h3><h3 id=-std-expand-legalize-std-operations-to-be-convertible-to-llvm><code>-std-expand</code>: Legalize std operations to be convertible to LLVM.&nbsp;<a class=headline-hash href=#-std-expand-legalize-std-operations-to-be-convertible-to-llvm>¶</a></h3><h3 id=-tensor-constant-bufferize-bufferize-tensor-constants><code>-tensor-constant-bufferize</code>: Bufferize tensor constants.&nbsp;<a class=headline-hash href=#-tensor-constant-bufferize-bufferize-tensor-constants>¶</a></h3><p>This pass bufferizes tensor constants.</p><p>This pass needs to be a module pass because it inserts std.global_memref
ops into the module, which cannot be done safely from a function pass due to
multi-threading. Most other bufferization passes can run in parallel at
function granularity.</p><h2 id=tosa-dialect-passes>TOSA Dialect Passes&nbsp;<a class=headline-hash href=#tosa-dialect-passes>¶</a></h2><h3 id=-tosa-make-broadcastable-tosa-rank-reshape-to-enable-broadcasting><code>-tosa-make-broadcastable</code>: TOSA rank Reshape to enable Broadcasting&nbsp;<a class=headline-hash href=#-tosa-make-broadcastable-tosa-rank-reshape-to-enable-broadcasting>¶</a></h3><p>Pass that enables broadcast by making all input arrays have the same
number of dimensions. Insert RESHAPE operations to prepend dimensions
of size one until the number of dimensions is equal. Implements
approach similar to step 1 of Numpy 4-step broadcasting:
<a href=https://numpy.org/doc/stable/reference/ufuncs.html#broadcasting>https://numpy.org/doc/stable/reference/ufuncs.html#broadcasting</a></p><div class=edit-meta><br></div><nav class=pagination><a class="nav nav-prev" href=/docs/PassManagement/ title="Pass Infrastructure"><i class="fas fa-arrow-left" aria-hidden=true></i>Prev - Pass Infrastructure</a>
<a class="nav nav-next" href=/docs/PatternRewriter/ title="Pattern Rewriting : Generic DAG-to-DAG Rewriting">Next - Pattern Rewriting : Generic DAG-to-DAG Rewriting <i class="fas fa-arrow-right" aria-hidden=true></i></a></nav><footer><p class=powered>Powered by <a href=https://gohugo.io>Hugo</a>. Theme by <a href=https://themes.gohugo.io/hugo-theme-techdoc/>TechDoc</a>. Designed by <a href=https://github.com/thingsym/hugo-theme-techdoc>Thingsym</a>.</p></footer></main><div class=sidebar><nav class=slide-menu><ul><li><a href=https://mlir.llvm.org/>Home</a></li><li><a href=/talks/>Talks and Related Publications</a></li><li><a href=/users/>Users of MLIR</a></li><li class=has-sub-menu><a href=/getting_started/>Getting Started<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/getting_started/Debugging/>Debugging</a></li><li><a href=/getting_started/Faq/>FAQ</a></li><li><a href=/getting_started/Contributing/>How to Contribute</a></li><li><a href=/getting_started/DeveloperGuide/>Developer Guide</a></li><li><a href=/getting_started/openprojects/>Open Projects</a></li><li><a href=/getting_started/Glossary/>Glossary</a></li><li><a href=/getting_started/TestingGuide/>Testing Guide</a></li></ul></li><li class="parent has-sub-menu"><a href=/docs/>Code Documentation<span class="mark opened">-</span></a><ul class=sub-menu><li class=has-sub-menu><a href=/docs/Bindings/>Bindings<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Bindings/Python/>MLIR Python Bindings</a></li></ul></li><li class=has-sub-menu><a href=/docs/Dialects/>Dialects<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Dialects/Builtin/></a></li><li><a href=/docs/Dialects/OpenACCDialect/>'acc' Dialect</a></li><li><a href=/docs/Dialects/Affine/>'affine' Dialect</a></li><li><a href=/docs/Dialects/ArmNeon/>'arm_neon' Dialect</a></li><li><a href=/docs/Dialects/AsyncDialect/>'async' Dialect</a></li><li><a href=/docs/Dialects/AVX512/>'avx512' Dialect</a></li><li><a href=/docs/Dialects/GPU/>'gpu' Dialect</a></li><li><a href=/docs/Dialects/Linalg/>'linalg' Dialect</a></li><li><a href=/docs/Dialects/LLVM/>'llvm' Dialect</a></li><li><a href=/docs/Dialects/LLVMArmNeon/>'llvm_arm_neon' Dialect</a></li><li><a href=/docs/Dialects/LLVMArmSve/>'llvm_arm_sve' Dialect</a></li><li><a href=/docs/Dialects/LLVMAVX512/>'llvm_avx512' Dialect</a></li><li><a href=/docs/Dialects/NVVMDialect/>'nvvm' Dialect</a></li><li><a href=/docs/Dialects/OpenMPDialect/>'omp' Dialect</a></li><li><a href=/docs/Dialects/PDLOps/>'pdl' Dialect</a></li><li><a href=/docs/Dialects/PDLInterpOps/>'pdl_interp' Dialect</a></li><li><a href=/docs/Dialects/QuantDialect/>'quant' Dialect</a></li><li><a href=/docs/Dialects/ROCDLDialect/>'rocdl' Dialect</a></li><li><a href=/docs/Dialects/SCFDialect/>'scf' Dialect</a></li><li><a href=/docs/Dialects/ShapeDialect/>'shape' Dialect</a></li><li><a href=/docs/Dialects/SPIR-V/>'spv' Dialect</a></li><li><a href=/docs/Dialects/Standard/>'std' Dialect</a></li><li><a href=/docs/Dialects/TensorOps/>'tensor' Dialect</a></li><li><a href=/docs/Dialects/Vector/>'vector' Dialect</a></li><li><a href=/docs/Dialects/TOSA/>Tensor Operator Set Architecture (TOSA) Dialect</a></li></ul></li><li><a href=/docs/TensorPasses/></a></li><li><a href=/docs/EDSC/>Background: declarative builders API</a></li><li><a href=/docs/Bufferization/>Bufferization on MLIR</a></li><li><a href=/docs/ConversionToLLVMDialect/>Conversion to the LLVM Dialect</a></li><li><a href=/docs/Diagnostics/>Diagnostic Infrastructure</a></li><li><a href=/docs/DialectConversion/>Dialect Conversion</a></li><li><a href=/docs/Interfaces/>Interfaces</a></li><li><a href=/docs/CAPI/>MLIR C API</a></li><li><a href=/docs/LangRef/>MLIR Language Reference</a></li><li><a href=/docs/Canonicalization/>Operation Canonicalization</a></li><li><a href=/docs/OpDefinitions/>Operation Definition Specification (ODS)</a></li><li><a href=/docs/PassManagement/>Pass Infrastructure</a></li><li class=active><a href=/docs/Passes/>Passes</a></li><li><a href=/docs/PatternRewriter/>Pattern Rewriting : Generic DAG-to-DAG Rewriting</a></li><li><a href=/docs/Quantization/>Quantization</a></li><li class=has-sub-menu><a href=/docs/Rationale/>Rationale<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Rationale/RationaleGenericDAGRewriter/>Generic DAG Rewriter Infrastructure Rationale</a></li><li><a href=/docs/Rationale/RationaleLinalgDialect/>Linalg Dialect Rationale: The Case For Compiler-Friendly Custom Operations</a></li><li><a href=/docs/Rationale/Rationale/>MLIR Rationale</a></li><li><a href=/docs/Rationale/MLIRForGraphAlgorithms/>MLIR: Incremental Application to Graph Algorithms in ML Frameworks</a></li><li><a href=/docs/Rationale/RationaleSimplifiedPolyhedralForm/>MLIR: The case for a simplified polyhedral form</a></li><li><a href=/docs/Rationale/UsageOfConst/>Usage of 'const' in MLIR, for core IR types</a></li></ul></li><li><a href=/docs/ShapeInference/>Shape Inference</a></li><li><a href=/docs/SPIRVToLLVMDialectConversion/>SPIR-V Dialect to LLVM Dialect conversion manual</a></li><li><a href=/docs/SymbolsAndSymbolTables/>Symbols and Symbol Tables</a></li><li><a href=/docs/DeclarativeRewrites/>Table-driven Declarative Rewrite Rule (DRR)</a></li><li><a href=/docs/Traits/>Traits</a></li><li class=has-sub-menu><a href=/docs/Tutorials/>Tutorials<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/CreatingADialect/>Creating a Dialect</a></li><li><a href=/docs/Tutorials/DefiningAttributesAndTypes/>Defining Dialect Attributes and Types</a></li><li><a href=/docs/Tutorials/QuickstartRewrites/>Quickstart tutorial to adding MLIR graph rewrite</a></li><li class=has-sub-menu><a href=/docs/Tutorials/Toy/>Toy Tutorial<span class="mark closed">+</span></a><ul class=sub-menu><li><a href=/docs/Tutorials/Toy/Ch-1/>Chapter 1: Toy Language and AST</a></li><li><a href=/docs/Tutorials/Toy/Ch-2/>Chapter 2: Emitting Basic MLIR</a></li><li><a href=/docs/Tutorials/Toy/Ch-3/>Chapter 3: High-level Language-Specific Analysis and Transformation</a></li><li><a href=/docs/Tutorials/Toy/Ch-4/>Chapter 4: Enabling Generic Transformation with Interfaces</a></li><li><a href=/docs/Tutorials/Toy/Ch-5/>Chapter 5: Partial Lowering to Lower-Level Dialects for Optimization</a></li><li><a href=/docs/Tutorials/Toy/Ch-6/>Chapter 6: Lowering to LLVM and CodeGeneration</a></li><li><a href=/docs/Tutorials/Toy/Ch-7/>Chapter 7: Adding a Composite Type to Toy</a></li></ul></li><li><a href=/docs/Tutorials/UnderstandingTheIRStructure/>Understanding the IR Structure</a></li></ul></li></ul></li></ul></nav><div class=sidebar-footer></div></div></div><a href=# id=backtothetop-fixed class=backtothetop data-backtothetop-duration=600 data-backtothetop-easing=easeOutQuart data-backtothetop-fixed-fadein=1000 data-backtothetop-fixed-fadeout=1000 data-backtothetop-fixed-bottom=10 data-backtothetop-fixed-right=20><span class="fa-layers fa-fw"><i class="fas fa-circle"></i><i class="fas fa-arrow-circle-up"></i></span></a></div></body></html>